{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import CifarNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dress-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "tf = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "testloader = torch.utils.data.DataLoader(torchvision.datasets.CIFAR10('data/', train=False, download=True, transform=tf), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def net_time(model_class, testloader):\n",
    "    \n",
    "    model = model_class()\n",
    "    t_start = time.time()\n",
    "    x, _ = next(iter(testloader))\n",
    "    model(x)\n",
    "    t_end = time.time()\n",
    "    t = t_end - t_start\n",
    "    return t\n",
    "\n",
    "def net_acc(model_class, state_dict, testloader):\n",
    "\n",
    "    model = model_class()\n",
    "    model.load_state_dict(state_dict)\n",
    "    num_correct = 0\n",
    "    inputs, targets = next(iter(testloader))\n",
    "    outputs = model(inputs)\n",
    "    predicted = torch.argmax(outputs, dim=1) \n",
    "    num_correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    accuracy = num_correct/32\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "periodic-preliminary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time unquantized: 0.028605937957763672 s\n",
      "Accuracy unquantized: 84.3750%\n"
     ]
    }
   ],
   "source": [
    "print(f'Time unquantized: {net_time(CifarNet, testloader)} s')\n",
    "print(f\"Accuracy unquantized: {net_acc(CifarNet, torch.load('state_dict.pt'), testloader):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sudden-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def f_sd(sd, endswith_key_string):\n",
    "    keys = [i for i in sd.keys() if i.endswith(endswith_key_string)]\n",
    "    if not keys:\n",
    "        raise KeyError(endswith_key_string)\n",
    "    return sd[keys[0]]\n",
    "\n",
    "#Quantized Conv2dReLU Module\n",
    "class QConv2dReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(QConv2dReLU, self).__init__()\n",
    "\n",
    "        self.weight = torch.nn.Parameter(torch.quantize_per_tensor(torch.Tensor(\n",
    "                out_channels, in_channels // 1, *(kernel_size, kernel_size)), scale=0.1, zero_point = 0, dtype=torch.qint8), requires_grad=False)\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(out_channels), requires_grad=False)\n",
    "\n",
    "        self.register_buffer('scale', torch.tensor(0.1))\n",
    "\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        self._prepack = self._prepare_prepack(self.weight, self.bias, stride, padding)\n",
    "        self._register_load_state_dict_pre_hook(self._sd_hook)\n",
    "\n",
    "    def _prepare_prepack(self, qweight, bias, stride, padding):\n",
    "        assert qweight.is_quantized, \"QConv2dReLU requires a quantized weight.\"\n",
    "        assert not bias.is_quantized, \"QConv2dReLU requires a float bias.\"\n",
    "        return torch.ops.quantized.conv2d_prepack(qweight, bias, stride=[stride, stride], dilation=[1,1], padding=[padding, padding], groups=1)\n",
    "\n",
    "    \n",
    "    def _sd_hook(self, state_dict, prefix, *_):\n",
    "        self._prepack = self._prepare_prepack(f_sd(state_dict, prefix + 'weight'), f_sd(state_dict, prefix + 'bias'),\n",
    "                                             self.stride, self.padding)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.ops.quantized.conv2d_relu(x, self._prepack, self.scale, 64)\n",
    "\n",
    "    \n",
    "#Quantized Linear Module\n",
    "class QLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(QLinear, self).__init__()\n",
    "\n",
    "        self.weight = torch.nn.Parameter(torch.quantize_per_tensor(torch.Tensor(out_features, in_features), scale=0.1, zero_point = 0, dtype=torch.qint8), requires_grad=False)\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(out_features))\n",
    "\n",
    "        self.register_buffer('scale', torch.tensor(0.1))\n",
    "        \n",
    "        self._prepack = self._prepare_prepack(self.weight, self.bias)\n",
    "        \n",
    "        self._register_load_state_dict_pre_hook(self._sd_hook)\n",
    "        \n",
    "    def _prepare_prepack(self, qweight, bias):\n",
    "        assert qweight.is_quantized, \"QConv2dReLU requires a quantized weight.\"\n",
    "        assert not bias.is_quantized, \"QConv2dReLU requires a float bias.\"\n",
    "        return torch.ops.quantized.linear_prepack(qweight, bias)\n",
    "    \n",
    "    def _sd_hook(self, state_dict, prefix, *_):\n",
    "        self._prepack = self._prepare_prepack(f_sd(state_dict, prefix + 'weight'), f_sd(state_dict, prefix + 'bias'))\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.ops.quantized.linear(x, self._prepack, self.scale, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "possible-forty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict of QConv2dReLU\n",
      "weight torch.qint8\n",
      "bias torch.float32\n",
      "scale torch.float32\n",
      "\n",
      "state_dict of QLinear\n",
      "weight torch.qint8\n",
      "bias torch.float32\n",
      "scale torch.float32\n"
     ]
    }
   ],
   "source": [
    "print('state_dict of QConv2dReLU')\n",
    "qconv2drelu = QConv2dReLU(3, 16)\n",
    "for key in qconv2drelu.state_dict(): print(key, qconv2drelu.state_dict()[key].dtype)\n",
    "print('\\nstate_dict of QLinear')\n",
    "qlinear = QLinear(10, 10)\n",
    "for key in qlinear.state_dict(): print(key, qlinear.state_dict()[key].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QCifarNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QCifarNet, self).__init__()\n",
    "        \n",
    "        self.register_buffer(\"scale\", torch.tensor(0.1))\n",
    "\n",
    "        self.conv1 = QConv2dReLU(3, 16, 3, 1, padding=1)\n",
    "        self.conv2 = QConv2dReLU(16,16, 3, 1, padding=1)\n",
    "\n",
    "        self.conv3 = QConv2dReLU(16, 32, 3, 1, padding=1)\n",
    "        self.conv4 = QConv2dReLU(32, 32, 3, 1, padding=1)\n",
    "\n",
    "        self.conv5 = QConv2dReLU(32, 64, 3, 1, padding=1)\n",
    "        self.conv6 = QConv2dReLU(64, 64, 3, 1, padding=1)\n",
    "\n",
    "        self.fc = QLinear(1024, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.quantize_per_tensor(x, scale=0.1, zero_point=64, dtype=torch.quint8)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.quantized.functional.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.nn.quantized.functional.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = torch.nn.quantized.functional.max_pool2d(x, 2)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        x = torch.dequantize(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unexpected-brass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time quantized: 0.015759706497192383 s\n"
     ]
    }
   ],
   "source": [
    "#We evaulate how fast the quantized verions of CifarNet is\n",
    "print(f\"Time quantized: {net_time(QCifarNet, testloader)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_scale(input):\n",
    "    return float(2*torch.max(torch.abs(torch.max(input)), torch.abs(torch.min(input))))/127.0\n",
    "\n",
    "def fuse_conv_bn_weights(conv_w, conv_b, bn_rm, bn_rv, bn_w, bn_b):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        conv_w: shape=(output_channels, in_channels, kernel_size, kernel_size)\n",
    "        conv_b: shape=(output_channels)\n",
    "        bn_rm:  shape=(output_channels)\n",
    "        bn_rv:  shape=(output_channels)\n",
    "        bn_w:   shape=(output_channels)\n",
    "        bn_b:   shape=(output_channels)\n",
    "    \n",
    "    Output:\n",
    "        fused_conv_w = shape=conv_w\n",
    "        fused_conv_b = shape=conv_b\n",
    "    \"\"\"\n",
    "    bn_eps = 1e-05\n",
    "\n",
    "    fused_conv = torch.zeros(conv_w.shape)\n",
    "    fused_bias = torch.zeros(conv_b.shape)\n",
    "    \n",
    "    std = torch.sqrt(bn_rv + bn_eps)\n",
    "    scale = bn_w / std\n",
    "\n",
    "    fused_conv = conv_w * scale.reshape()\n",
    "    fused_bias = scale * (conv_b - bn_rm) + bn_b\n",
    "\n",
    "    return fused_conv, fused_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints keys from quantized net\n",
    "qnet = QCifarNet()\n",
    "qsd = qnet.state_dict()\n",
    "for key in qsd: print(key, qsd[key].dtype)\n",
    "\n",
    "sd = torch.load('state_dict.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
